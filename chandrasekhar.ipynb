{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "270de681-4957-4fd3-b489-17436c76c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from utils import fit_vi\n",
    "torch.set_default_dtype(torch.float64)\n",
    "from tqdm.notebook import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from perseus import Perseus\n",
    "from viqa import VIQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "05a0a700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -1247.697538\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1324.469598\n",
      "         Iterations: 2\n",
      "         Function evaluations: 34\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1386.627877\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1425.681462\n",
      "         Iterations: 2\n",
      "         Function evaluations: 32\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1433.033035\n",
      "         Iterations: 2\n",
      "         Function evaluations: 36\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -94.347363\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -149.327595\n",
      "         Iterations: 2\n",
      "         Function evaluations: 21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -203.195405\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -247.302127\n",
      "         Iterations: 2\n",
      "         Function evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -275.846465\n",
      "         Iterations: 2\n",
      "         Function evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -298.692557\n",
      "         Iterations: 2\n",
      "         Function evaluations: 43\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -394.315125\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -471.854486\n",
      "         Iterations: 2\n",
      "         Function evaluations: 49\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -519.953136\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -534.564848\n",
      "         Iterations: 2\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -156.329921\n",
      "         Iterations: 2\n",
      "         Function evaluations: 21\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -227.779991\n",
      "         Iterations: 2\n",
      "         Function evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -290.137847\n",
      "         Iterations: 2\n",
      "         Function evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -334.329297\n",
      "         Iterations: 2\n",
      "         Function evaluations: 41\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -356.409854\n",
      "         Iterations: 2\n",
      "         Function evaluations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -229.744496\n",
      "         Iterations: 2\n",
      "         Function evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -314.831915\n",
      "         Iterations: 2\n",
      "         Function evaluations: 33\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -384.895199\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -430.259544\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -447.604704\n",
      "         Iterations: 1\n",
      "         Function evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -183.959574\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -260.810692\n",
      "         Iterations: 2\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -326.030832\n",
      "         Iterations: 2\n",
      "         Function evaluations: 32\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -370.470772\n",
      "         Iterations: 2\n",
      "         Function evaluations: 37\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -390.575592\n",
      "         Iterations: 2\n",
      "         Function evaluations: 43\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -209.807921\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -291.373522\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -359.288884\n",
      "         Iterations: 2\n",
      "         Function evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -404.169517\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -422.646004\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -194.315208\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -273.073747\n",
      "         Iterations: 2\n",
      "         Function evaluations: 39\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -339.362320\n",
      "         Iterations: 2\n",
      "         Function evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -383.954918\n",
      "         Iterations: 2\n",
      "         Function evaluations: 37\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -403.386273\n",
      "         Iterations: 2\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -203.291145\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -283.680983\n",
      "         Iterations: 2\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -350.907199\n",
      "         Iterations: 2\n",
      "         Function evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -395.657885\n",
      "         Iterations: 2\n",
      "         Function evaluations: 34\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -414.528553\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -197.985268\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -277.412400\n",
      "         Iterations: 2\n",
      "         Function evaluations: 39\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -344.082821\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -388.737181\n",
      "         Iterations: 2\n",
      "         Function evaluations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -407.936819\n",
      "         Iterations: 2\n",
      "         Function evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -201.085332\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -281.075431\n",
      "         Iterations: 2\n",
      "         Function evaluations: 38\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -348.070019\n",
      "         Iterations: 2\n",
      "         Function evaluations: 39\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -392.779649\n",
      "         Iterations: 2\n",
      "         Function evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -411.786222\n",
      "         Iterations: 2\n",
      "         Function evaluations: 39\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -199.261583\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -278.920657\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -345.724348\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -390.401124\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -409.520983\n",
      "         Iterations: 2\n",
      "         Function evaluations: 43\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -200.330186\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -280.183273\n",
      "         Iterations: 2\n",
      "         Function evaluations: 32\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -347.098753\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -391.794660\n",
      "         Iterations: 2\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.848040\n",
      "         Iterations: 2\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -199.702571\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -279.441729\n",
      "         Iterations: 2\n",
      "         Function evaluations: 36\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -346.291530\n",
      "         Iterations: 2\n",
      "         Function evaluations: 39\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -390.976162\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.068552\n",
      "         Iterations: 2\n",
      "         Function evaluations: 44\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -200.070677\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -279.876661\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -346.764977\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -391.456208\n",
      "         Iterations: 2\n",
      "         Function evaluations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.525706\n",
      "         Iterations: 2\n",
      "         Function evaluations: 41\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -199.854604\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -279.621364\n",
      "         Iterations: 2\n",
      "         Function evaluations: 32\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -346.487068\n",
      "         Iterations: 2\n",
      "         Function evaluations: 28\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -391.174422\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.257353\n",
      "         Iterations: 2\n",
      "         Function evaluations: 42\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -199.981376\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -279.771149\n",
      "         Iterations: 2\n",
      "         Function evaluations: 32\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -346.650119\n",
      "         Iterations: 2\n",
      "         Function evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -391.339744\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.414794\n",
      "         Iterations: 2\n",
      "         Function evaluations: 41\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -199.906980\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -279.683247\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -346.554434\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -391.242720\n",
      "         Iterations: 2\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.322398\n",
      "         Iterations: 2\n",
      "         Function evaluations: 43\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -199.950630\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -279.734823\n",
      "         Iterations: 2\n",
      "         Function evaluations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -346.610574\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -391.299650\n",
      "         Iterations: 2\n",
      "         Function evaluations: 29\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.376609\n",
      "         Iterations: 2\n",
      "         Function evaluations: 43\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -199.925014\n",
      "         Iterations: 2\n",
      "         Function evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -279.704557\n",
      "         Iterations: 2\n",
      "         Function evaluations: 32\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -346.577631\n",
      "         Iterations: 2\n",
      "         Function evaluations: 30\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -391.266242\n",
      "         Iterations: 2\n",
      "         Function evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -410.344796\n",
      "         Iterations: 2\n",
      "         Function evaluations: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/cpjttnqd1835ygkgtppb3hp00000gn/T/ipykernel_62253/1407243657.py:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pd.DataFrame({\"q1\":float(qk[0]),\"q2\":float(qk[1]),\"q3\":float(qk[2]),\"q4\":float(qk[3]),\"q5\":float(qk[4])}, index=[0])],\n",
      "/var/folders/dd/cpjttnqd1835ygkgtppb3hp00000gn/T/ipykernel_62253/1407243657.py:19: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_table=pd.concat([result_table,\n",
      "/var/folders/dd/cpjttnqd1835ygkgtppb3hp00000gn/T/ipykernel_62253/1407243657.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Qk+=float(qk[j])\n",
      "/var/folders/dd/cpjttnqd1835ygkgtppb3hp00000gn/T/ipykernel_62253/1407243657.py:52: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sol.append(float(res))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.03</td>\n",
       "      <td>56.19</td>\n",
       "      <td>55.76</td>\n",
       "      <td>53.41</td>\n",
       "      <td>49.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.19</td>\n",
       "      <td>32.99</td>\n",
       "      <td>36.16</td>\n",
       "      <td>36.51</td>\n",
       "      <td>34.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.62</td>\n",
       "      <td>46.76</td>\n",
       "      <td>48.01</td>\n",
       "      <td>46.37</td>\n",
       "      <td>42.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.56</td>\n",
       "      <td>38.85</td>\n",
       "      <td>41.17</td>\n",
       "      <td>40.54</td>\n",
       "      <td>37.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.89</td>\n",
       "      <td>43.53</td>\n",
       "      <td>45.19</td>\n",
       "      <td>43.92</td>\n",
       "      <td>40.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35.78</td>\n",
       "      <td>40.80</td>\n",
       "      <td>42.83</td>\n",
       "      <td>41.93</td>\n",
       "      <td>38.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37.61</td>\n",
       "      <td>42.41</td>\n",
       "      <td>44.22</td>\n",
       "      <td>43.09</td>\n",
       "      <td>39.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36.54</td>\n",
       "      <td>41.47</td>\n",
       "      <td>43.41</td>\n",
       "      <td>42.41</td>\n",
       "      <td>38.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37.16</td>\n",
       "      <td>42.02</td>\n",
       "      <td>43.88</td>\n",
       "      <td>42.81</td>\n",
       "      <td>39.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.80</td>\n",
       "      <td>41.70</td>\n",
       "      <td>43.60</td>\n",
       "      <td>42.57</td>\n",
       "      <td>39.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37.01</td>\n",
       "      <td>41.89</td>\n",
       "      <td>43.77</td>\n",
       "      <td>42.71</td>\n",
       "      <td>39.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36.89</td>\n",
       "      <td>41.78</td>\n",
       "      <td>43.67</td>\n",
       "      <td>42.63</td>\n",
       "      <td>39.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36.96</td>\n",
       "      <td>41.84</td>\n",
       "      <td>43.73</td>\n",
       "      <td>42.68</td>\n",
       "      <td>39.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36.92</td>\n",
       "      <td>41.80</td>\n",
       "      <td>43.69</td>\n",
       "      <td>42.65</td>\n",
       "      <td>39.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.94</td>\n",
       "      <td>41.83</td>\n",
       "      <td>43.71</td>\n",
       "      <td>42.67</td>\n",
       "      <td>39.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36.93</td>\n",
       "      <td>41.81</td>\n",
       "      <td>43.70</td>\n",
       "      <td>42.66</td>\n",
       "      <td>39.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.94</td>\n",
       "      <td>41.82</td>\n",
       "      <td>43.71</td>\n",
       "      <td>42.66</td>\n",
       "      <td>39.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36.93</td>\n",
       "      <td>41.82</td>\n",
       "      <td>43.71</td>\n",
       "      <td>42.66</td>\n",
       "      <td>39.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36.93</td>\n",
       "      <td>41.82</td>\n",
       "      <td>43.71</td>\n",
       "      <td>42.66</td>\n",
       "      <td>39.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36.93</td>\n",
       "      <td>41.82</td>\n",
       "      <td>43.71</td>\n",
       "      <td>42.66</td>\n",
       "      <td>39.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       q1     q2     q3     q4     q5\n",
       "0   10.00  10.00  10.00  10.00  10.00\n",
       "1   55.03  56.19  55.76  53.41  49.14\n",
       "2   27.19  32.99  36.16  36.51  34.38\n",
       "3   42.62  46.76  48.01  46.37  42.30\n",
       "4   33.56  38.85  41.17  40.54  37.47\n",
       "5   38.89  43.53  45.19  43.92  40.22\n",
       "6   35.78  40.80  42.83  41.93  38.58\n",
       "7   37.61  42.41  44.22  43.09  39.53\n",
       "8   36.54  41.47  43.41  42.41  38.97\n",
       "9   37.16  42.02  43.88  42.81  39.30\n",
       "10  36.80  41.70  43.60  42.57  39.11\n",
       "11  37.01  41.89  43.77  42.71  39.22\n",
       "12  36.89  41.78  43.67  42.63  39.15\n",
       "13  36.96  41.84  43.73  42.68  39.19\n",
       "14  36.92  41.80  43.69  42.65  39.17\n",
       "15  36.94  41.83  43.71  42.67  39.18\n",
       "16  36.93  41.81  43.70  42.66  39.18\n",
       "17  36.94  41.82  43.71  42.66  39.18\n",
       "18  36.93  41.82  43.71  42.66  39.18\n",
       "19  36.93  41.82  43.71  42.66  39.18\n",
       "20  36.93  41.82  43.71  42.66  39.18"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fmin_powell\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "#Define the parameters for each firm\n",
    "parameters=np.matrix([[10,5,1.2],[8,5,1.1],[6,5,1],[4,5,0.9],[2,5,0.8]])\n",
    "\n",
    "#Define a table to output the iterations information\n",
    "result_table=pd.DataFrame(columns=[\"q1\", \"q2\", \"q3\", \"q4\", \"q5\"])\n",
    "\n",
    "#Select initial point and uncertainty measure\n",
    "qk=np.matrix([[10],[10],[10],[10],[10]]) \n",
    "result_table=pd.concat([result_table,\n",
    "                        pd.DataFrame({\"q1\":float(qk[0]),\"q2\":float(qk[1]),\"q3\":float(qk[2]),\"q4\":float(qk[3]),\"q5\":float(qk[4])}, index=[0])], \n",
    "                        ignore_index=True)\n",
    "\n",
    "len_uncert=0.005\n",
    "termination=False\n",
    "k=0\n",
    "N= len(qk)\n",
    "\n",
    "while not termination: \n",
    "    \n",
    "    sol=[]\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        #Compute the total supply without the value of the ith player\n",
    "        Qk=0\n",
    "        for j in range(N): \n",
    "            if j !=i: \n",
    "                Qk+=float(qk[j])\n",
    "        \n",
    "        # Set the values of the parameters\n",
    "        ci=parameters[i,0]\n",
    "        Li=parameters[i,1]\n",
    "        Bi=parameters[i,2]\n",
    "\n",
    "        #Solve the optimization problem \n",
    "        fun=lambda qi: (qi*(5000**(1/1.1)*(qi+Qk)**(-1/1.1))-ci*qi-(Bi/(Bi+1))*(Li**(-1/Bi))*(qi**((Bi+1)/Bi)))*-1\n",
    "        #bnds = [(0, None)]\n",
    "        #res= minimize(fun, 100, method='SLSQP', bounds=bnds)\n",
    "        res=fmin_powell(fun,40)\n",
    "        \n",
    "        #Save the solution\n",
    "        sol.append(float(res))\n",
    "\n",
    "        \n",
    "    result_table=pd.concat([result_table, \n",
    "                            pd.DataFrame({\"q1\":np.round(sol[0],2),\"q2\":np.round(sol[1],2),\"q3\":np.round(sol[2],2),\"q4\":np.round(sol[3],2),\"q5\":np.round(sol[4],2)}, index=[0])], ignore_index=True)\n",
    "    \n",
    "    #Set the value of the new solution\n",
    "    qk1=np.matrix([[sol[0]],[sol[1]],[sol[2]],[sol[3]],[sol[4]]]) \n",
    "    \n",
    "    #Check termination criteria\n",
    "    if LA.norm(qk1-qk)<=len_uncert: \n",
    "        termination=True\n",
    "    \n",
    "    #Update solution\n",
    "    k+=1\n",
    "    qk=qk1\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "result_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "137143b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/cpjttnqd1835ygkgtppb3hp00000gn/T/ipykernel_62253/3640500978.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_table=pd.concat([result_table,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.66</td>\n",
       "      <td>9.78</td>\n",
       "      <td>9.90</td>\n",
       "      <td>10.02</td>\n",
       "      <td>10.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.26</td>\n",
       "      <td>9.38</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.61</td>\n",
       "      <td>9.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.87</td>\n",
       "      <td>8.98</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.50</td>\n",
       "      <td>8.60</td>\n",
       "      <td>8.71</td>\n",
       "      <td>8.81</td>\n",
       "      <td>8.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>6.91</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>6.91</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>6.91</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>6.91</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>6.91</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        q1     q2     q3     q4     q5\n",
       "0    10.00  10.00  10.00  10.00  10.00\n",
       "1     9.66   9.78   9.90  10.02  10.14\n",
       "2     9.26   9.38   9.49   9.61   9.72\n",
       "3     8.87   8.98   9.09   9.20   9.31\n",
       "4     8.50   8.60   8.71   8.81   8.92\n",
       "..     ...    ...    ...    ...    ...\n",
       "496   6.91   7.00   7.08   7.16   7.25\n",
       "497   6.91   7.00   7.08   7.16   7.25\n",
       "498   6.91   7.00   7.08   7.16   7.25\n",
       "499   6.91   7.00   7.08   7.16   7.25\n",
       "500   6.91   7.00   7.08   7.16   7.25\n",
       "\n",
       "[501 rows x 5 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import fmin_powell\n",
    "import torch\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "#Define the parameters for each firm\n",
    "parameters=torch.tensor(np.matrix([[10,5,1.2],[8,5,1.1],[6,5,1],[4,5,0.9],[2,5,0.8]]))\n",
    "\n",
    "#Define a table to output the iterations information\n",
    "result_table=pd.DataFrame(columns=[\"q1\", \"q2\", \"q3\", \"q4\", \"q5\"])\n",
    "\n",
    "#Select initial point and uncertainty measure\n",
    "qk=[torch.tensor(np.matrix([[10.],[10.],[10.],[10.],[10.]]), requires_grad=True)]\n",
    "qs = [np.array(qk[0].detach()), np.array(qk[0].detach())]\n",
    "\n",
    "optimizer = VIQA(qk, L=20, p_order = 2, last_iterate=True, B0=0.1, delta=0.1)\n",
    "result_table=pd.concat([result_table,\n",
    "                        pd.DataFrame({\"q1\":float(qk[0][0]),\"q2\":float(qk[0][1]),\"q3\":float(qk[0][2]),\"q4\":float(qk[0][3]),\"q5\":float(qk[0][4])}, index=[0])], \n",
    "                        ignore_index=True)\n",
    "\n",
    "c = parameters[:,0].view(-1, 1)\n",
    "L = parameters[:,1].view(-1, 1)\n",
    "B = parameters[:,2].view(-1, 1)\n",
    "\n",
    "for epoch in range(500):    \n",
    "    \n",
    "    q = qs[-2]\n",
    "    Q_k_1 = torch.ones(q.shape)*q.sum() - q\n",
    "\n",
    "    #Solve the optimization problem\n",
    "    def fun(q_k, Q_k_1):\n",
    "        qQ = q_k + Q_k_1\n",
    "        p = 5000**(1/1.1)*qQ**(-1/1.1)\n",
    "        p_ = 5000**(1/1.1) * (-1/1.1) * qQ**(-1/1.1 - 1)\n",
    "        return c*q_k +  B / (B + 1) * L**(1/B) * q_k**((B+1)/B) - p - q_k*p_\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        return fun(qk[0], Q_k_1)\n",
    "    \n",
    "    optimizer.step(closure)\n",
    "    \n",
    "    q = np.array(qk[0].detach())\n",
    "    qs += [q]\n",
    "    result_table=pd.concat([result_table, \n",
    "                            pd.DataFrame({\"q1\":np.round(q[0],2),\"q2\":np.round(q[1],2),\"q3\":np.round(q[2],2),\"q4\":np.round(q[3],2),\"q5\":np.round(q[4],2)}, index=[0])], \n",
    "                            ignore_index=True)\n",
    "result_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = torch.tensor(range(1,d+1)) - 0.5\n",
    "A = torch.zeros(d,d)\n",
    "c = 1 - 1e-5\n",
    "for i in range(d):\n",
    "    A[i] = mu[i] / (torch.tensor(range(1,d+1))+i) * c / (2 * d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 1 / (1 - A @ x)\n",
    "\n",
    "def f1(x):\n",
    "    return x[0] - 1 / (1 - A @ x[0])\n",
    "\n",
    "def f2(x):\n",
    "    return 1 + A @ x * x\n",
    "\n",
    "def F(x):\n",
    "    return x[0]  - x[0] * A @ x[0] - 1\n",
    "\n",
    "def gap(x):\n",
    "    return torch.linalg.norm(x[0] - f(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.3219e-07),\n",
       " tensor(1.3126e-07),\n",
       " tensor(1.3034e-07),\n",
       " tensor(1.2942e-07),\n",
       " tensor(1.2850e-07)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(d)\n",
    "norms = []\n",
    "x_hist = [x]\n",
    "for j in range(1000):\n",
    "    x1 = f(x)\n",
    "    norms += [(x1-x).norm()]\n",
    "    x = x1 +0.\n",
    "    x_hist += [x]\n",
    "norms[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665cd905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5257, 2.4617])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(3.0706e-06),\n",
       " tensor(3.0601e-06),\n",
       " tensor(3.0496e-06),\n",
       " tensor(3.0391e-06),\n",
       " tensor(3.0287e-06)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(d)\n",
    "norms = []\n",
    "for j in range(1000):\n",
    "    x2 = f2(x)\n",
    "    norms += [(x2-x).norm()]\n",
    "    x = x2 +0.\n",
    "norms[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5255, 2.4608])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70c35898034409ba5aa7a3a5bb55a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m param \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mzeros(d, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m VIQA(param, L\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.1\u001b[39m, p_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, last_iterate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, B0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m gaps_EG, grads_EG, times_EG \u001b[38;5;241m=\u001b[39m fit_vi(optimizer, iters_num \u001b[38;5;241m=\u001b[39m N, F\u001b[38;5;241m=\u001b[39mf1, param\u001b[38;5;241m=\u001b[39mparam, gap\u001b[38;5;241m=\u001b[39mgap, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-50\u001b[39m)\n\u001b[1;32m      5\u001b[0m gaps_EG[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:]\n",
      "File \u001b[0;32m~/Desktop/master-s-projects/utils.py:32\u001b[0m, in \u001b[0;36mfit_vi\u001b[0;34m(optimizer, iters_num, F, param, gap, precision, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m gaps\u001b[38;5;241m.\u001b[39mappend(func_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     31\u001b[0m st \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[1;32m     33\u001b[0m timed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mst\n\u001b[1;32m     34\u001b[0m times\u001b[38;5;241m.\u001b[39mappend(times[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m timed)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/master-s-projects/viqa.py:346\u001b[0m, in \u001b[0;36mVIQA.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    342\u001b[0m             p\u001b[38;5;241m.\u001b[39mzero_()\u001b[38;5;241m.\u001b[39madd_(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_average\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    344\u001b[0m state_common[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m params\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "param = [torch.zeros(d, requires_grad=True)]\n",
    "optimizer = VIQA(param, L=.1, p_order = 2, last_iterate=True, B0=0.001, delta=0.001)\n",
    "gaps_EG, grads_EG, times_EG = fit_vi(optimizer, iters_num = N, F=f1, param=param, gap=gap, precision=1e-50)\n",
    "gaps_EG[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14a574bf0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(gaps_EG[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.8388e-10], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.0610, 1.1065, 1.1388, 1.1643, 1.1853, 1.2032, 1.2186, 1.2322, 1.2441,\n",
       "         1.2548, 1.2645, 1.2732, 1.2812, 1.2885, 1.2952, 1.3014, 1.3072, 1.3125,\n",
       "         1.3175, 1.3221], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75980c69",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     func_loss \u001b[38;5;241m=\u001b[39m gap_torch(param)\n\u001b[1;32m     15\u001b[0m     gaps\u001b[38;5;241m.\u001b[39mappend(func_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 17\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     iters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(gaps)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [6], line 139\u001b[0m, in \u001b[0;36mPerseus.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    137\u001b[0m             state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_order \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecond_order_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_v\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params:\n",
      "Cell \u001b[0;32mIn [6], line 99\u001b[0m, in \u001b[0;36mPerseus.second_order_step\u001b[0;34m(self, params, operator_v)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msecond_order_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, operator_v):\n\u001b[1;32m     98\u001b[0m     operator_vec \u001b[38;5;241m=\u001b[39m tuple_to_vector(operator_v)\n\u001b[0;32m---> 99\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_vec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     b \u001b[38;5;241m=\u001b[39m operator_vec\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    101\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubproblem_solver(A, b, L\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, inverse_vector\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_inverse_vector)\n",
      "Cell \u001b[0;32mIn [6], line 110\u001b[0m, in \u001b[0;36mPerseus.jacobian\u001b[0;34m(self, params, operator_vector)\u001b[0m\n\u001b[1;32m    108\u001b[0m full_jacobian \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m operator_vector:\n\u001b[0;32m--> 110\u001b[0m     temp_jvp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     full_jacobian\u001b[38;5;241m.\u001b[39mappend(tuple_to_vector(temp_jvp))\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(full_jacobian)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/autograd/__init__.py:411\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    408\u001b[0m         grad_outputs_\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    422\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    424\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = 10\n",
    "x = torch.ones(nd)\n",
    "x.requires_grad = True\n",
    "param = [x,y]\n",
    "optimizer = Perseus(param, L=10, p_order=2, last_iterate=True)\n",
    "gaps = []\n",
    "iters = 0\n",
    "while iters < 2000:\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        return F_torch(param)\n",
    "    func_loss = gap_torch(param)\n",
    "    gaps.append(func_loss.item())\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    iters += 1\n",
    "\n",
    "plt.plot(gaps)\n",
    "plt.title('Perseus 2 order')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Gap')\n",
    "plt.show()\n",
    "\n",
    "PERSEUS2 = gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "x = torch.ones(n) / n\n",
    "x.requires_grad = True\n",
    "y = torch.ones(n) / n\n",
    "y.requires_grad = True\n",
    "param = [x,y]\n",
    "optimizer = Perseus(param, L=0.5, p_order=1, last_iterate=True)\n",
    "gaps = []\n",
    "iters = 0\n",
    "while iters < 2000:\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        return F_torch(param)\n",
    "    func_loss = gap_torch(param)\n",
    "    gaps.append(func_loss.item())\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    iters += 1\n",
    "\n",
    "plt.plot(gaps)\n",
    "plt.title('Perseus 1 order')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Gap')\n",
    "plt.show()\n",
    "\n",
    "PERSEUS1 = gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514823a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from OPTAMI.utils import tuple_to_vec\n",
    "class Heracles(Optimizer):\n",
    "    MONOTONE = False\n",
    "    SKIP_TEST_LOGREG = True\n",
    "    def __init__(self,\n",
    "                    params,\n",
    "                    L: float = 1., delta: float = 0., B0: float = 0., memory: int = 10, p_order: int = 1, last_iterate: bool = True,\n",
    "                 verbose: bool = True, testing: bool = False, qn = 'BFGS', half = 1\n",
    "                ):\n",
    "        super().__init__(params, dict(L=L))\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.testing = testing\n",
    "        self.qn = qn\n",
    "        self.half = half\n",
    "\n",
    "        self.last_iterate = last_iterate\n",
    "        self.p_order = p_order\n",
    "        self.L = L\n",
    "        self.delta = delta\n",
    "        self.B0 = B0\n",
    "        self.memory = memory\n",
    "\n",
    "        if len(self.param_groups) != 1:\n",
    "            raise ValueError(\"Superfast doesn't support per-parameter options \"\n",
    "                             \"(parameter groups)\")\n",
    "        group = self.param_groups[0]\n",
    "        params = group['params']\n",
    "        p = next(iter(params))\n",
    "        state_common = self.state[p]\n",
    "        state_common['k'] = 0\n",
    "        state_common['S_qn'] = []\n",
    "        state_common['Y_qn'] = []\n",
    "\n",
    "        if not self.last_iterate:\n",
    "            state_common['lambda_sum'] = 0.\n",
    "\n",
    "        # Initialization of intermediate points\n",
    "        for p in params:\n",
    "            state = self.state[p]\n",
    "            state['x0'] = p.detach().clone()\n",
    "            state['x'] = state['x0'].clone()\n",
    "            state['v'] = state['x0'].clone()\n",
    "            state['s'] = torch.zeros_like(state['x'])\n",
    "\n",
    "            if not self.last_iterate:\n",
    "                state['x_average'] = torch.zeros_like(p)\n",
    "\n",
    "    #lambda_computation\n",
    "    @torch.no_grad()\n",
    "    def compute_lambda(self, L, params, delta=0.):\n",
    "        bound = (1 / (20 * self.p_order - 8) + 1 / (10 * self.p_order + 2)) / 2\n",
    "        den = 1\n",
    "        for m in range(1, self.p_order+1):\n",
    "            den *= m\n",
    "        norm = 0.\n",
    "        with torch.no_grad():\n",
    "            for p in params:\n",
    "                state = self.state[p]\n",
    "                norm += (p - state['v']).square().sum()**.5\n",
    "        return  bound / (L * norm ** (self.p_order-1)/den + delta)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def full_inverse_vector(self, A, b, tau):\n",
    "        return torch.linalg.inv(A + torch.diag(torch.ones_like(b)).mul_(tau)) @ b\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def subproblem_solver(self, A, b, L, inverse_vector, delta=0., tau_up = 0.01 , tau_low = 0., max_iter = 20):\n",
    "\n",
    "        j = 0\n",
    "        flag = True\n",
    "        while flag and j < max_iter:\n",
    "            h = - inverse_vector(A,b,5 * L * tau_up + delta)\n",
    "            norm = torch.linalg.norm(h).item()\n",
    "            if norm > tau_up:\n",
    "                tau_up *= 2\n",
    "            else:\n",
    "                flag = False\n",
    "            j+=1\n",
    "\n",
    "        j = 0\n",
    "        h = torch.zeros_like(b)\n",
    "        norm = 0.\n",
    "        criteria = 100.\n",
    "        while j < max_iter and criteria > L / 2 * norm ** 2: #and abs(tau - norm) > 0.001\n",
    "            tau = (tau_up + tau_low) / 2\n",
    "            h = - inverse_vector(A,b,5*L/2*tau+ delta)\n",
    "            norm = torch.linalg.norm(h).item()\n",
    "            #print(tau, norm)\n",
    "            if norm < tau:\n",
    "                tau_up = tau + 0.5\n",
    "            else:\n",
    "                tau_low = tau + 0.5\n",
    "            j += 1\n",
    "            c = b + A @ h + 5 * L / 2 * torch.linalg.norm(h) * h + delta * h\n",
    "            criteria = torch.norm(c)\n",
    "        return h#, criteria\n",
    "\n",
    "    def Broyd_qn(self, params, S, Y, B0):\n",
    "        V_qn = []\n",
    "        C_qn = []\n",
    "        U_qn = []\n",
    "        g = tuple_to_vec.tuple_to_vector(list(params))\n",
    "        B = torch.diag(torch.ones_like(g)).mul_(B0)\n",
    "\n",
    "        if len(S) == 0:\n",
    "            return V_qn, C_qn, U_qn, B\n",
    "\n",
    "        for i in range(len(S)):\n",
    "            s = tuple_to_vec.tuple_to_vector(S[-1-i])\n",
    "            v = s.clone()\n",
    "            y = tuple_to_vec.tuple_to_vector(Y[-1-i])\n",
    "            u = y - B @ s\n",
    "            c = 1/v.mul(v).sum()\n",
    "            C_qn.insert(0, c)\n",
    "            V_qn.insert(0, v)\n",
    "            U_qn.insert(0, u)\n",
    "            B += u.outer(v) * c\n",
    "        return V_qn, C_qn, U_qn, B\n",
    "    \n",
    "    def Broyd_qn_damped(self, params, S, Y, B0, memory):\n",
    "        V_qn = []\n",
    "        C_qn = []\n",
    "        U_qn = []\n",
    "        g = tuple_to_vec.tuple_to_vector(list(params))\n",
    "        B = torch.diag(torch.ones_like(g)).mul_(B0)\n",
    "\n",
    "        if len(S) == 0:\n",
    "            return V_qn, C_qn, U_qn, B\n",
    "\n",
    "        for i in range(len(S)):\n",
    "            s = tuple_to_vec.tuple_to_vector(S[-1-i])\n",
    "            v = s.clone()\n",
    "            y = tuple_to_vec.tuple_to_vector(Y[-1-i])\n",
    "            u = y - B @ s\n",
    "            c = 1/(v.mul(v).sum() * (memory + 1))\n",
    "            C_qn.insert(0, c)\n",
    "            V_qn.insert(0, v)\n",
    "            U_qn.insert(0, u)\n",
    "            B += u.outer(v) * c\n",
    "        return V_qn, C_qn, U_qn, B\n",
    "    \n",
    "    def BFGS_qn(self, params, S, Y, B0, memory = 0):\n",
    "        V_qn = []\n",
    "        C_qn = []\n",
    "        U_qn = []\n",
    "        g = tuple_to_vec.tuple_to_vector(list(params))\n",
    "        B = torch.diag(torch.ones_like(g)).mul_(B0)\n",
    "\n",
    "        if len(S) == 0:\n",
    "            return V_qn, C_qn, U_qn, B\n",
    "\n",
    "        for i in range(1, len(S)):\n",
    "            s = tuple_to_vec.tuple_to_vector(S[-1-i])\n",
    "            y = tuple_to_vec.tuple_to_vector(Y[-1-i])\n",
    "\n",
    "            #part 1\n",
    "            c1 = 1/(y.mul(s).sum() * (memory + 1))\n",
    "            C_qn.insert(0, c1)\n",
    "            V_qn.insert(0, s)\n",
    "            U_qn.insert(0, y)\n",
    "\n",
    "\n",
    "            #part 2\n",
    "            u = B @ s\n",
    "            c2 = - 1 / s.mul(u).sum()\n",
    "            C_qn.insert(0, c2)\n",
    "            V_qn.insert(0, u)\n",
    "            U_qn.insert(0, u)\n",
    "            B += u.outer(u) * c2\n",
    "            B += y.outer(y) * c1\n",
    "\n",
    "\n",
    "        return V_qn, C_qn, U_qn, B\n",
    "\n",
    "    #step 3\n",
    "    def qn_step(self, params, operator_v, S, Y, B0=0):\n",
    "        b = tuple_to_vec.tuple_to_vector(operator_v).detach().clone()\n",
    "\n",
    "        if self.qn == 'BFGS':\n",
    "            V_qn, C_qn, U_qn, B = self.BFGS_qn(params, S, Y, B0, memory=0)\n",
    "        elif self.qn == 'BFGS_broid':\n",
    "            V_qn, C_qn, U_qn, B1 = self.BFGS_qn(params, S, Y, B0, memory=0)\n",
    "            V_qn, C_qn, U_qn, B2 = self.Broyd_qn(params, S, Y, B0)\n",
    "            B = (B1 + B2) / (1 + self.half)\n",
    "        elif self.qn == 'BFGS_damped':\n",
    "            V_qn, C_qn, U_qn, B1 = self.BFGS_qn(params, S, Y, B0, memory=0)\n",
    "            V_qn, C_qn, U_qn, B2 = self.Broyd_qn_damped(params, S, Y, B0, memory=0)\n",
    "            B = (B1 + B2) / (1 + self.half)\n",
    "\n",
    "        elif self.qn == 'damped_BFGS':\n",
    "            V_qn, C_qn, U_qn, B = self.BFGS_qn(params, S, Y, B0, memory=self.memory)\n",
    "        elif self.qn == 'damped_BFGS_broid':\n",
    "            V_qn, C_qn, U_qn, B1 = self.BFGS_qn(params, S, Y, B0, memory=self.memory)\n",
    "            V_qn, C_qn, U_qn, B2 = self.Broyd_qn(params, S, Y, B0)\n",
    "            B = (B1 + B2) / (1 + self.half)\n",
    "        elif self.qn == 'damped_BFGS_damped':\n",
    "            V_qn, C_qn, U_qn, B1 = self.BFGS_qn(params, S, Y, B0, memory=self.memory)\n",
    "            V_qn, C_qn, U_qn, B2 = self.Broyd_qn_damped(params, S, Y, B0, memory=self.memory)\n",
    "            B = (B1 + B2) / (1 + self.half)\n",
    "        elif self.qn == 'broyd':\n",
    "            V_qn, C_qn, U_qn, B = self.Broyd_qn(params, S, Y, B0)\n",
    "        elif self.qn == 'damped_broyd':\n",
    "            V_qn, C_qn, U_qn, B = self.Broyd_qn_damped(params, S, Y, B0, memory=self.memory)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        h = self.subproblem_solver(B, b, L = self.L, delta = self.delta, inverse_vector = self.full_inverse_vector)\n",
    "        h_tuple = tuple_to_vec.rollup_vector(h, list(params))\n",
    "        return h_tuple\n",
    "\n",
    "    def jacobian(self, params, operator_vector):\n",
    "        full_jacobian = []\n",
    "        for g in operator_vector:\n",
    "            temp_jvp = torch.autograd.grad(g, params, retain_graph=True)\n",
    "            full_jacobian.append(tuple_to_vec.tuple_to_vector(temp_jvp))\n",
    "        return torch.stack(full_jacobian)\n",
    "\n",
    "\n",
    "    def step(self, closure):\n",
    "\n",
    "        closure = torch.enable_grad()(closure)\n",
    "\n",
    "        assert len(self.param_groups) == 1\n",
    "        group = self.param_groups[0]\n",
    "        params = group['params']\n",
    "        p = next(iter(params))\n",
    "        state_common = self.state[p]\n",
    "\n",
    "\n",
    "        #step 2\n",
    "        with torch.no_grad():\n",
    "            for p in params:\n",
    "                state = self.state[p]\n",
    "                state['v'] = state['x0'] + state['s'] #/ self.L\n",
    "                p.zero_().add_(state['v'])\n",
    "\n",
    "        operator_v = closure()\n",
    "\n",
    "\n",
    "\n",
    "        h_tuple = self.qn_step(params, operator_v, S = state_common['S_qn'], Y = state_common['Y_qn'], B0 = self.B0)\n",
    "\n",
    "        state_common['S_qn'].insert(0, h_tuple)\n",
    "        if len(state_common['S_qn']) > self.memory:\n",
    "            state_common['S_qn'].pop()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for p, z in zip(params,h_tuple):\n",
    "                state = self.state[p]\n",
    "                p.add_(z)\n",
    "                state['x'] = p.clone().detach()\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for p in params:\n",
    "                state = self.state[p]\n",
    "                state['x'] = p.clone()\n",
    "\n",
    "        lamb = self.compute_lambda(self.L, params, delta=self.delta)\n",
    "        #lamb = 1.\n",
    "        operator_x = closure()\n",
    "\n",
    "        oper_dif = []\n",
    "        with torch.no_grad():\n",
    "            for g2, g1 in zip(operator_x,operator_v):\n",
    "                oper_dif.append(g2-g1)\n",
    "\n",
    "        state_common['Y_qn'].insert(0, oper_dif)\n",
    "        if len(state_common['Y_qn']) > self.memory:\n",
    "            state_common['Y_qn'].pop()\n",
    "\n",
    "\n",
    "        if not self.last_iterate:\n",
    "            state_common['lambda_sum'] += lamb\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for p, g in zip(params, operator_x):\n",
    "                state = self.state[p]\n",
    "                state['s'].sub_(g, alpha = lamb)\n",
    "\n",
    "                if not self.last_iterate:\n",
    "                    state['x_average'].mul_(state_common['lambda_sum']).add_(state['x'] * lamb)\n",
    "                    state_common['lambda_sum'] += lamb\n",
    "                    state['x_average'].div_(state_common['lambda_sum'])\n",
    "                    p.zero_().add_(state['x_average'])\n",
    "\n",
    "        state_common['k'] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "x = torch.ones(n) / n\n",
    "x.requires_grad = True\n",
    "y = torch.ones(n) / n\n",
    "y.requires_grad = True\n",
    "param = [x,y]\n",
    "optimizer = Heracles(param, L=50, p_order=2, last_iterate=True, delta=0.06, memory=20, B0=0.01, qn='damped_broyd', half=1)\n",
    "gaps = []\n",
    "iters = 0\n",
    "while iters < 2000:\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        return F_torch(param)\n",
    "    func_loss = gap_torch(param)\n",
    "    gaps.append(func_loss.item())\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    iters += 1\n",
    "\n",
    "plt.plot(gaps)\n",
    "plt.title('VIQA')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Gap')\n",
    "plt.show()\n",
    "\n",
    "damped_broyd = gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc3dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "x = torch.ones(n) / n\n",
    "x.requires_grad = True\n",
    "y = torch.ones(n) / n\n",
    "y.requires_grad = True\n",
    "param = [x,y]\n",
    "optimizer = Heracles(param, L=50, p_order=2, last_iterate=True, delta=0.06, memory=20, B0=0.01, qn='broyd', half=1)\n",
    "gaps = []\n",
    "iters = 0\n",
    "while iters < 2000:\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        return F_torch(param)\n",
    "    func_loss = gap_torch(param)\n",
    "    gaps.append(func_loss.item())\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    iters += 1\n",
    "\n",
    "plt.plot(gaps)\n",
    "plt.title('VIQA')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('Gap')\n",
    "plt.show()\n",
    "\n",
    "broyd = gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import ticker as mticker\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6))\n",
    "plt.tight_layout()\n",
    "\n",
    "N = 2000\n",
    "step = 100\n",
    "plt.semilogy(np.array(range(0,len(EG1[:N]),step)), EG1[:N:step], 'b-', label='EG', )\n",
    "plt.semilogy(np.array(range(0,len(PERSEUS1[:N]),step)), PERSEUS1[:N:step], 'm:', label='Perseus1')\n",
    "plt.semilogy(np.array(range(0,len(PERSEUS2[:N]),2*step)), PERSEUS2[:N:2*step], 'g--', label='Perseus2')\n",
    "plt.semilogy(np.array(range(0,len(damped_broyd[:N]),step)), damped_broyd[:N:step], 'r-.', label='VIQA Damped Broyden')\n",
    "plt.semilogy(np.array(range(0,len(broyd[:N]),step)), broyd[:N:step], 'v-.', label='VIQA Broyden')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Iteration, k')\n",
    "plt.ylabel('Gap')\n",
    "\n",
    "# plt.axis([-1000, 200000, 8e-16, 2.,], emit=True)\n",
    "plt.minorticks_on()\n",
    "# plt.xticks(rotation=-70)\n",
    "#plt.savefig('GAP Iteration.pdf', format='pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import ticker as mticker\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6))\n",
    "plt.tight_layout()\n",
    "\n",
    "N = 2000\n",
    "step = 100\n",
    "plt.semilogy(2*np.array(range(0,len(EG1[:N]),step)), EG1[:N:step], 'b-', label='EG', )\n",
    "plt.semilogy(2*np.array(range(0,len(PERSEUS1[:N]),step)), PERSEUS1[:N:step], 'm:', label='Perseus1')\n",
    "plt.semilogy((n+1)*np.array(range(0,len(PERSEUS2[:N//4]),2*step)), PERSEUS2[:N//4:2*step], 'g--', label='Perseus2')\n",
    "plt.semilogy(2*np.array(range(0,len(damped_broyd[:N]),step)), damped_broyd[:N:step], 'r-.', label='VIQA Damped Broyden')\n",
    "plt.semilogy(2*np.array(range(0,len(broyd[:N]),step)), broyd[:N:step], 'v-.', label='VIQA Broyden')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('JVP/F(x) computations')\n",
    "plt.ylabel('Gap')\n",
    "\n",
    "# plt.axis([-1000, 200000, 8e-16, 2.,], emit=True)\n",
    "plt.minorticks_on()\n",
    "# plt.xticks(rotation=-70)\n",
    "#plt.savefig('GAP JVP.pdf', format='pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a940b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
